{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7853a11",
   "metadata": {},
   "source": [
    "## Runnning with gammapy-dev/IRF_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04af29",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27bf135a-5ee4-4ca1-8549-6bf07929003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from gammapy.maps import Map\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from gammapy.modeling import Fit,  Parameters, Covariance , Parameter\n",
    "from gammapy.datasets import MapDataset ,Datasets, FluxPointsDataset\n",
    "from gammapy.modeling.models import (\n",
    "    PowerLawSpectralModel,\n",
    "    SkyModel,\n",
    "    PointSpatialModel,\n",
    "    PowerLawNormSpectralModel,\n",
    "    Models,\n",
    "    SpatialModel,\n",
    "    FoVBackgroundModel,\n",
    "    PiecewiseNormSpectralModel,\n",
    ")\n",
    "from gammapy.estimators import TSMapEstimator, ExcessMapEstimator\n",
    "from gammapy.estimators import FluxPoints, FluxPointsEstimator\n",
    "from scipy.interpolate import interp2d\n",
    "\n",
    "from regions import CircleSkyRegion, RectangleSkyRegion\n",
    "import yaml\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import Dataset_load \n",
    "\n",
    "from  Dataset_Setup import Setup, GaussianCovariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815c93a2-a7a6-4592-8b29-3fb8289b3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "rc(\"font\", **{\"family\": \"serif\", \"serif\": [\"Computer Modern\"]})\n",
    "rc(\"text\", usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de988df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eeeaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Dataset_load.load_config()\n",
    "awo, aw, ewo, ew = c['_colors']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0c45f4e-6432-405e-86b7-649e254c0950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined_1TeV_10per\n"
     ]
    }
   ],
   "source": [
    "livetime = c['livetime']\n",
    "zero = c['zero'] \n",
    "norm = c['norm'] \n",
    "tilt = c['tilt'] \n",
    "bias = c['bias'] \n",
    "resolution = c['resolution'] \n",
    "magnitude = c['magnitude'] \n",
    "corrlength = c['corrlength']\n",
    "sys = c['sys'] \n",
    "folder = c['folder']\n",
    "parameter_names = c['parameter_names']        \n",
    "nbidx = 0\n",
    "print(sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b828754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amplitude\n",
      "index\n",
      "lambda_\n"
     ]
    }
   ],
   "source": [
    "parameter_names_1  = set(list(np.array(parameter_names).ravel()))\n",
    "for p in parameter_names_1:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0399d4",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b24b18ac-af52-48ac-bd1e-f03d21457fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dataset:\n",
      "/home/wecapstor1/caph/mppi045h/nuisance_summary/Dataset/datasets/dataset-simulated-2.154434690031884-hr.fits.gz\n",
      "reference 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset_input  = Dataset_load.create_asimov(model = c['model'], source = c['source'], \n",
    "                                               livetime = f\"{livetime}-hr\",\n",
    "                                        parameters = None) \n",
    "setup = Setup(dataset_input=dataset_input)\n",
    "#setup.set_up_irf_sys(bias, resolution, norm, tilt)\n",
    "dataset_asimov, dataset_asimov_N = setup.run()\n",
    "# irf model\n",
    "setup.set_irf_model(dataset_asimov_N)\n",
    "dataset_asimov, dataset_asimov_N = setup.apply_config_settings(dataset_asimov, dataset_asimov_N, c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec637604-dbf7-4501-9012-2bf4c302d233",
   "metadata": {},
   "source": [
    "## Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cdaa02-9c45-4596-a45c-09d2a78eb1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amplitude', 'index', 'lambda_'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_names_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6589e22-4b65-4ef2-a364-0fa01a829dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_scan(dataset, note):\n",
    "        \n",
    "    fit_cor = Fit(store_trace=False)\n",
    "    result_cor = fit_cor.run(dataset)\n",
    "    print(dataset_asimov.models)\n",
    "    \n",
    "    results = []\n",
    "    for parname1 in parameter_names_1 :\n",
    "        if parname1 == 'lambda_':\n",
    "            print(\"scanning\",  parname1)\n",
    "            dataset.models.parameters[parname1].scan_n_values=numpoints\n",
    "            result = fit_cor.stat_profile(dataset,\n",
    "                                 dataset.models.parameters[parname1],\n",
    "                                reoptimize = True\n",
    "                                )\n",
    "\n",
    "            contour_write = dict()\n",
    "            for k in result.keys():\n",
    "                print(k)\n",
    "                if k != \"fit_results\":\n",
    "                    contour_write[k] = [float(_) for _ in result[k]]#.tolist()\n",
    "            print(contour_write)\n",
    "            with open(f\"../{c['folder']}/data/4_scan_{note}_{parname1}_{numpoints}.yml\", \"w\") as outfile:\n",
    "                yaml.dump(contour_write, outfile, default_flow_style=False)\n",
    "\n",
    "            results.append(result)\n",
    "    return results\n",
    "        \n",
    "def read_in_scan(note):\n",
    "    results = []\n",
    "    for parname1 in parameter_names_1 :\n",
    "        try:\n",
    "            with open(f\"../{c['folder']}/data/4_scan_{note}_{parname1}_{numpoints}.yml\", \"r\") as stream:\n",
    "                contour = yaml.safe_load(stream)\n",
    "        except:\n",
    "            with open(f\"../{c['folder']}/data/4_scan_{note}_{parname1}.yml\", \"r\") as stream:\n",
    "                contour = yaml.safe_load(stream)\n",
    "        results.append(contour)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2201840-6c23-471d-b286-7152982bbb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 ms, sys: 376 Âµs, total: 27 ms\n",
      "Wall time: 27.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "numpoints = 20\n",
    "computing = 0\n",
    "if computing:\n",
    "    results = computing_scan(dataset_asimov, \"2.15h\")\n",
    "else:\n",
    "    results = read_in_scan(\"2.15h\")\n",
    "    path = f'../{folder}/data/0_model.yml'\n",
    "    dataset_asimov.models = Models.read(path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a09d6e7-599d-4612-b80e-23d72f04ea98",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Combined_1TeV_10per_PKSflare_crab_cutoff/data/4_scan_N_2.15h_amplitude.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m, in \u001b[0;36mread_in_scan\u001b[0;34m(note)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfolder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/data/4_scan_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnote\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparname1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnumpoints\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[1;32m     34\u001b[0m         contour \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(stream)\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/anaconda3/envs/gammapy-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Combined_1TeV_10per_PKSflare_crab_cutoff/data/4_scan_N_2.15h_amplitude_20.yml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:10\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m, in \u001b[0;36mread_in_scan\u001b[0;34m(note)\u001b[0m\n\u001b[1;32m     34\u001b[0m         contour \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(stream)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfolder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/data/4_scan_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnote\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparname1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.yml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m stream:\n\u001b[1;32m     37\u001b[0m         contour \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(stream)\n\u001b[1;32m     38\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(contour)\n",
      "File \u001b[0;32m/home/wecapstor1/caph/mppi045h/anaconda3/envs/gammapy-dev/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Combined_1TeV_10per_PKSflare_crab_cutoff/data/4_scan_N_2.15h_amplitude.yml'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "computing = 0\n",
    "numpoints = 20\n",
    "\n",
    "if computing:\n",
    "    dataset_asimov_N.models.parameters['lon_0'].frozen = True\n",
    "    dataset_asimov_N.models.parameters['lat_0'].frozen = True\n",
    "    \n",
    "    results_N = computing_scan(dataset_asimov_N, \"N_2.15h\")\n",
    "else:\n",
    "    results_N = read_in_scan(\"N_2.15h\")\n",
    "    try:\n",
    "        path = f'../{folder}/data/0_model_nui.yml'\n",
    "        dataset_asimov_N = Dataset_load.load_dataset_N(dataset_asimov_N, path,bkg_sys = False)        \n",
    "    except:\n",
    "        path = f'../{folder}/data/0_model_nui_1000.yml'\n",
    "        dataset_asimov_N = Dataset_load.load_dataset_N(dataset_asimov_N, path,bkg_sys = False)        \n",
    "        \n",
    "print(results_N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01551e25-99b6-4557-b5ea-7345e5e8592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetModels\n",
      "\n",
      "Component 0: SkyModel\n",
      "\n",
      "  Name                      : Crablog\n",
      "  Datasets names            : None\n",
      "  Spectral model type       : ExpCutoffPowerLawSpectralModel\n",
      "  Spatial  model type       : PointSpatialModel\n",
      "  Temporal model type       : \n",
      "  Parameters:\n",
      "    index                      :      2.300  +/-    0.00             \n",
      "    amplitude                  :   3.85e-11  +/- 0.0e+00 1 / (cm2 s TeV)\n",
      "    reference  (frozen)        :      1.000      TeV         \n",
      "    lambda_                    :      0.100  +/-    0.00 1 / TeV     \n",
      "    alpha      (frozen)        :      1.000                  \n",
      "    lon_0                      :    329.680  +/-    0.00 deg         \n",
      "    lat_0                      :    -30.222  +/-    0.00 deg         \n",
      "\n",
      "Component 1: FoVBackgroundModel\n",
      "\n",
      "  Name                      : dataset_N-bkg\n",
      "  Datasets names            : ['dataset_N']\n",
      "  Spectral model type       : PowerLawNormSpectralModel\n",
      "  Parameters:\n",
      "    norm                       :      1.000  +/-    0.00             \n",
      "    tilt                       :      0.000  +/-    0.00             \n",
      "    reference  (frozen)        :      1.000      TeV         \n",
      "\n",
      "Component 2: IRFModels\n",
      "\n",
      "  Name                      : dataset_N-irf\n",
      "  Datasets names            : dataset_N\n",
      "  EReco  model type         : ERecoIRFModel\n",
      "  Eff area  model type      : EffAreaIRFModel\n",
      "  PSF model type            : \n",
      "  Parameters:\n",
      "    bias               [prior] :      0.000  +/-    0.00             \n",
      "    resolution (frozen)        :      0.000                  \n",
      "    norm               [prior] :      0.000  +/-    0.00             \n",
      "    tilt               [prior] :      0.000  +/-    0.00             \n",
      "    reference  (frozen)        :      1.000      TeV         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset_asimov_N.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97a4a482-8669-4254-9ea0-6acadb37fab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12156862745098039, 0.47058823529411764, 0.7058823529411765]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import colors as s\n",
    "s.blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb63b561-fad7-4ad2-a195-6a5232590e81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(parameter_names_1):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m#if p == 'index':\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m         stat_profile_N \u001b[38;5;241m=\u001b[39m \u001b[43mresults_N\u001b[49m[i]\n\u001b[1;32m     13\u001b[0m         stat_profile \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     15\u001b[0m         stat_profile_N[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_scan\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(stat_profile_N[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat_scan\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_N' is not defined"
     ]
    }
   ],
   "source": [
    "import upper_limit_18_02\n",
    "\n",
    "colors_ = [s.blue, s.orange,\n",
    "          s.lblue, s.lorange]\n",
    "\n",
    "colors_ = [awo[0] , aw[0],\n",
    "           awo[1] , aw[1]]\n",
    "\n",
    "for i, p in enumerate(parameter_names_1):\n",
    "    #if p == 'index':\n",
    "    if True:\n",
    "        stat_profile_N = results_N[i]\n",
    "        stat_profile = results[i]\n",
    "\n",
    "        stat_profile_N['stat_scan'] -= np.min(stat_profile_N['stat_scan'])\n",
    "        stat_profile['stat_scan'] -= np.min(stat_profile['stat_scan'])\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ll_N_a = stat_profile_N.copy()\n",
    "        case = 'spectral'\n",
    "        if p == 'sigma':\n",
    "            case = 'spatial'\n",
    "            \n",
    "        amplitude_err = dataset_asimov.models[0].parameters[p].error\n",
    "        amplitude = dataset_asimov.models[0].parameters[p].value\n",
    "        amplitude_err_N = dataset_asimov_N.models[0].parameters[p].error\n",
    "        amplitude_N = dataset_asimov_N.models[0].parameters[p].value\n",
    "\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "            \n",
    "        ### LIKELIHOOD\n",
    "        # scan\n",
    "        ll_a = stat_profile.copy()\n",
    "        ul_a = upper_limit_18_02.upper_limit(ll_a,0,0,  name=f'{dataset_asimov.models[0].name}.{case}.{p}_scan')\n",
    "        L_a, x_a = ul_a.interpolate()\n",
    "        plt.plot(x_a, L_a(x_a),label = \"-2log (L)\", linestyle = 'dashed', color = colors_[0])\n",
    "    \n",
    "        ylim= ax.get_ylim()\n",
    "        ymax = 2#ylim[1]\n",
    "        min_, er_neg, er_pos = ul_a.likelihood_error_asymmetric()\n",
    "        min_ = min_[0]; er_neg = er_neg[0]; er_pos = er_pos[0]; \n",
    "        dataset_asimov.models.parameters[p].error_n = er_neg\n",
    "        dataset_asimov.models.parameters[p].error_p = er_pos\n",
    "        \n",
    "        factor = 1\n",
    "        if p == 'amplitude':\n",
    "            factor = 1e11\n",
    "\n",
    "        ax.fill_between(  [min_-er_neg, min_+ er_pos], ylim[0], ymax, alpha = 0.5, color=colors_[2],\n",
    "                        label = f'1$\\sigma$ error (Scan): -{er_neg*factor:.2} +{er_pos*factor:.2} ')\n",
    "     \n",
    "        \n",
    "        ax.vlines(amplitude-amplitude_err, ylim[0], ymax, color = colors_[0], linestyle ='dotted')\n",
    "        ax.vlines(amplitude+amplitude_err, ylim[0], ymax, color = colors_[0], linestyle ='dotted',\n",
    "                 label =  f'1$\\sigma$ error (Minuit): {amplitude_err*factor:.2}')\n",
    "\n",
    "           \n",
    "        ### POSTERIOR\n",
    "        # scan\n",
    "        ul_N_a = upper_limit_18_02.upper_limit(ll_N_a,0,0, \n",
    "                                               name=f'{dataset_asimov.models[0].name}.{case}.{p}_scan')\n",
    "        L_N_a, x_N_a = ul_N_a.interpolate()\n",
    "        plt.plot(x_N_a, L_N_a(x_N_a),label = \"-2log (P)\", color = colors_[1])\n",
    "        \n",
    "        \n",
    "        min_N, er_negN, er_posN = ul_N_a.likelihood_error_asymmetric()\n",
    "        min_N = min_N[0]; er_negN = er_negN[0]; er_posN = er_posN[0]; \n",
    "        dataset_asimov_N.models.parameters[p].error_n = er_negN\n",
    "        dataset_asimov_N.models.parameters[p].error_p = er_posN\n",
    "\n",
    "\n",
    "        ax.fill_between(  [min_N-er_negN, min_N+ er_posN], ylim[0], ymax, alpha = 0.5, color = colors_[3],\n",
    "                        label = f'1$\\sigma$ error (Scan): -{er_negN*factor:.5} +{er_posN*factor:.5} ')\n",
    "        ax.vlines(amplitude_N-amplitude_err_N, ylim[0], ymax,color = colors_[1] ,\n",
    "                  linestyles='dotted'\n",
    "                 )\n",
    "        ax.vlines(amplitude_N+amplitude_err_N, ylim[0], ymax,color = colors_[1],\n",
    "                  linestyles='dotted',\n",
    "                    label = f'1$\\sigma$ error (Minuit): $\\pm${amplitude_err_N*factor:.5}')\n",
    "                 \n",
    "        nn = 2\n",
    "        #ax.set_xlim(amplitude_N-amplitude_err_N*nn, \n",
    "        #           amplitude_N+amplitude_err_N*nn)\n",
    "        ax.set_ylim(np.min(stat_profile['stat_scan'])-0.5,\n",
    "                    np.min(stat_profile['stat_scan'])+ 3)\n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "        xx = ax.get_xlim()\n",
    "        alpha = 0.6\n",
    "        ax.hlines(0, xx[0], xx[1], color = 'grey', alpha = alpha)\n",
    "        ax.hlines(1, xx[0], xx[1], color = 'grey', alpha = alpha)\n",
    "        if p == 'amplitude':\n",
    "            str_= \"[$\\\\mathrm{TeV^{-1}\\\\,s^{-1}\\\\,cm^{-2}}$]\"\n",
    "            plt.xlabel(f\"Source strength \" + str_) \n",
    "        else:\n",
    "            plt.xlabel(p)\n",
    "        plt.ylabel(\"-2log (L) [arb. unit]\")\n",
    "        plt.legend(ncol = 2)\n",
    "\n",
    "    fig.savefig(f\"../{c['folder']}/plots/4_scan_{p}.pdf\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3346f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../{folder}/data/0_model_nui_livetime_{livetime}_np.yml'\n",
    "dataset_asimov_N.models.write(path, overwrite = 1)\n",
    "\n",
    "path = f'../{folder}/data/0_model_livetime_{livetime}_np.yml'\n",
    "dataset_asimov.models.write(path, overwrite = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95db6d8-c134-4b05-817b-3ebce0a994d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_asimov_N.models.parameters['index'].error)\n",
    "print(dataset_asimov_N.models.parameters['index'].error_n)\n",
    "print(dataset_asimov_N.models.parameters['index'].error_p)\n",
    "print(dataset_asimov_N.models.parameters['index'].value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b292b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_asimov.models.parameters['index'].error)\n",
    "print(dataset_asimov.models.parameters['index'].error_n)\n",
    "print(dataset_asimov.models.parameters['index'].error_p)\n",
    "print(dataset_asimov.models.parameters['index'].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7e4b55-557c-4024-8be7-071baac96b59",
   "metadata": {},
   "source": [
    "## Minos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a7d60-4942-4eee-8bff-ca5cf0bf2048",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = c['livetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e503cc1-a5ab-4f04-b413-530d28f8cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "compute_minos = 0\n",
    "if compute_minos :\n",
    "    fit_cor = Fit(store_trace=False)\n",
    "    result_cor = fit_cor.run(dataset_asimov)\n",
    "    result_cor.minuit.minos()\n",
    "   \n",
    "\n",
    "    minos_model = Models(dataset_asimov.models.copy() )\n",
    "    for p in result_cor.minuit.parameters:\n",
    "        p_ = p[8:]\n",
    "        factor = 1 \n",
    "        if p_ == \"amplitude\":\n",
    "            factor = dataset_asimov.models.parameters['amplitude'].scale\n",
    "        \n",
    "        minos_model.parameters[p_].error_n = fit_cor.minuit.merrors[p].lower* factor\n",
    "        minos_model.parameters[p_].error_p = fit_cor.minuit.merrors[p].upper* factor\n",
    "    minos_model.write(f'../{folder}/data/4_minos_error_{lt}.yaml', overwrite = True)\n",
    "\n",
    "\n",
    "    fit_cor_N = Fit(store_trace=False)\n",
    "    result_cor_N = fit_cor_N.run(dataset_asimov_N)\n",
    "    result_cor_N.minuit.minos()\n",
    "\n",
    "    minos_model_N = Models(dataset_asimov_N.models.copy() )\n",
    "    for p in result_cor_N.minuit.parameters:\n",
    "        p_ = p[8:]\n",
    "        print(p_)\n",
    "        factor = 1 \n",
    "        if p_ == \"amplitude\":\n",
    "            factor = dataset_asimov.models.parameters['amplitude'].scale\n",
    "        minos_model_N.parameters[p_].error_n = fit_cor_N.minuit.merrors[p].lower* factor\n",
    "        minos_model_N.parameters[p_].error_p = fit_cor_N.minuit.merrors[p].upper* factor\n",
    "        print(fit_cor_N.minuit.merrors[p].lower* factor)\n",
    "    minos_model_N.write(f'../{folder}/data/4_minos_error_{lt}_nui.yaml', overwrite = True)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "else:\n",
    "    minos_model_N = Models.read(f'../{folder}/data/4_minos_error_{lt}_nui.yaml')    \n",
    "    minos_model = Models.read(f'../{folder}/data/4_minos_error_{lt}.yaml')\n",
    "    \n",
    "minos_model_N.parameters['lambda_'].error_n *= 0.01\n",
    "minos_model_N.parameters['lambda_'].error_p *= 0.01\n",
    "\n",
    "minos_model.parameters['lambda_'].error_n *= 0.1\n",
    "minos_model.parameters['lambda_'].error_p *= 0.1\n",
    "\n",
    "minos_model_N.parameters['index'].value = dataset_asimov_N.models.parameters['index'].value\n",
    "minos_model_N.parameters['lambda_'].value = dataset_asimov_N.models.parameters['lambda_'].value\n",
    "minos_model_N.parameters['amplitude'].value = dataset_asimov_N.models.parameters['amplitude'].value\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d08fabd-6c7c-48ed-9753-f13dd03a88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minos_model.parameters['index'].error)\n",
    "print(minos_model.parameters['index'].error_n)\n",
    "print(minos_model.parameters['index'].error_p)\n",
    "print(minos_model.parameters['index'].value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff42a3f-a01e-471c-9bb7-44d4b9dd38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_asimov.models.parameters['index'].error)\n",
    "print(dataset_asimov.models.parameters['index'].error_n)\n",
    "print(dataset_asimov.models.parameters['index'].error_p)\n",
    "print(dataset_asimov.models.parameters['index'].value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743aa7e-abcd-437e-81f9-3d5b8768cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_asimov_N.models.parameters['index'].error_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c7e2e-904e-4367-8487-bedede0d091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import upper_limit_18_02\n",
    "\n",
    "colors_ = [s.blue, s.orange,\n",
    "          s.lblue, s.lorange]\n",
    "\n",
    "colors_ = [awo[0] , aw[0],\n",
    "           awo[1] , aw[1]]\n",
    "\n",
    "for i, p in enumerate(parameter_names_1):\n",
    "    #if p == 'index':\n",
    "    if True:\n",
    "        print(p)\n",
    "        stat_profile_N = results_N[i]\n",
    "        stat_profile = results[i]\n",
    "\n",
    "        stat_profile_N['stat_scan'] -= np.min(stat_profile_N['stat_scan'])\n",
    "        stat_profile['stat_scan'] -= np.min(stat_profile['stat_scan'])\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ll_N_a = stat_profile_N.copy()\n",
    "        case = 'spectral'\n",
    "        if p == 'sigma':\n",
    "            case = 'spatial'\n",
    "            \n",
    "        amplitude_err = dataset_asimov.models[0].parameters[p].error\n",
    "        amplitude = dataset_asimov.models[0].parameters[p].value\n",
    "        amplitude_err_N = dataset_asimov_N.models[0].parameters[p].error\n",
    "        amplitude_N = dataset_asimov_N.models[0].parameters[p].value\n",
    "\n",
    "        fig, ax = plt.subplots(1,1)\n",
    "            \n",
    "        ### LIKELIHOOD\n",
    "        # scan\n",
    "        ll_a = stat_profile.copy()\n",
    "        ul_a = upper_limit_18_02.upper_limit(ll_a,0,0,  name=f'{dataset_asimov.models[0].name}.{case}.{p}_scan')\n",
    "        L_a, x_a = ul_a.interpolate()\n",
    "        plt.plot(x_a, L_a(x_a),label = \"-2log (L)\", linestyle = 'dashed', color = colors_[0])\n",
    "    \n",
    "        ylim= ax.get_ylim()\n",
    "        ymax = 2#ylim[1]\n",
    "        min_, er_neg, er_pos = ul_a.likelihood_error_asymmetric()\n",
    "        min_ = min_[0]; er_neg = er_neg[0]; er_pos = er_pos[0]; \n",
    "        dataset_asimov.models.parameters[p].error_n = er_neg\n",
    "        dataset_asimov.models.parameters[p].error_p = er_pos\n",
    "        \n",
    "        factor = 1\n",
    "        if p == 'amplitude':\n",
    "            factor = 1e11\n",
    "\n",
    "        ax.fill_between(  [np.nan, np.nan], ylim[0], ymax,  alpha = 0.5, color=colors_[2],\n",
    "                        label = f'1$\\sigma$ error (Scan): -{er_neg*factor:.4} +{er_pos*factor:.4} ')\n",
    "     \n",
    "        \n",
    "        ax.vlines(amplitude-amplitude_err, ylim[0], ymax, color = colors_[0], linestyle ='dotted')\n",
    "        ax.vlines(amplitude+amplitude_err, ylim[0], ymax, color = colors_[0], linestyle ='dotted',\n",
    "                 label =  f'1$\\sigma$ error (Minuit): {amplitude_err*factor:.4}')\n",
    "         ## minos \n",
    "        # without nui      \n",
    "        par = minos_model.parameters[p]\n",
    "        value, error_n, error_p  = par.value, par.error_n, par.error_p\n",
    "        print(value)\n",
    "        \n",
    "        ax.vlines(value+error_n, ylim[0], ymax,color = 'tab:orange' ,\n",
    "                  linestyles='dashed'\n",
    "                 )\n",
    "        ax.vlines(value+error_p, ylim[0], ymax,color = 'tab:orange',\n",
    "                  linestyles='dashed',\n",
    "                    label = f'1$\\sigma$ error (Minos): {error_n*factor:.4} +{error_p*factor:.4} ')\n",
    "        \n",
    "           \n",
    "        ### POSTERIOR\n",
    "        # scan\n",
    "        ul_N_a = upper_limit_18_02.upper_limit(ll_N_a,0,0, \n",
    "                                               name=f'{dataset_asimov.models[0].name}.{case}.{p}_scan')\n",
    "        L_N_a, x_N_a = ul_N_a.interpolate()\n",
    "        plt.plot(x_N_a, L_N_a(x_N_a),label = \"-2log (P)\", color = colors_[1])\n",
    "        \n",
    "        \n",
    "        min_N, er_negN, er_posN = ul_N_a.likelihood_error_asymmetric()\n",
    "        min_N = min_N[0]; er_negN = er_negN[0]; er_posN = er_posN[0]; \n",
    "        dataset_asimov_N.models.parameters[p].error_n = er_negN\n",
    "        dataset_asimov_N.models.parameters[p].error_p = er_posN\n",
    "\n",
    "\n",
    "        ax.fill_between(  [min_N-er_negN, min_N+ er_posN], ylim[0], ymax, alpha = 0.5, color = colors_[3],\n",
    "                        label = f'1$\\sigma$ error (Scan): -{er_negN*factor:.4} +{er_posN*factor:.4} ')\n",
    "        ax.vlines(amplitude_N-amplitude_err_N, ylim[0], ymax,color = colors_[1] ,\n",
    "                  linestyles='dotted'\n",
    "                 )\n",
    "        ax.vlines(amplitude_N+amplitude_err_N, ylim[0], ymax,color = colors_[1],\n",
    "                  linestyles='dotted',\n",
    "                    label = f'1$\\sigma$ error (Minuit): $\\pm${amplitude_err_N*factor:.2}')\n",
    "        ## minos \n",
    "        # with nui\n",
    "        par = minos_model_N.parameters[p]\n",
    "        value, error_n, error_p  = par.value, par.error_n, par.error_p\n",
    "        print(value)\n",
    "        ax.vlines(value+error_n, ylim[0], ymax,color = 'purple' ,\n",
    "                  linestyles='dashed'\n",
    "                 )\n",
    "        ax.vlines(value+error_p, ylim[0], ymax,color = 'purple',\n",
    "                  linestyles='dashed',\n",
    "                    label = f'1$\\sigma$ error (Minos): {error_n*factor:.4} +{error_p*factor:.4} ')\n",
    "                   \n",
    "              \n",
    "            \n",
    "        nn = 5\n",
    "        #ax.set_xlim(value-error_n*nn, \n",
    "        #           value+error_p*nn)\n",
    "        ax.set_ylim(np.min(stat_profile['stat_scan'])-0.5,\n",
    "                    np.min(stat_profile['stat_scan'])+ 3)\n",
    "\n",
    "        \n",
    "        \n",
    "        ax.fill_between(  [min_-er_neg, min_+ er_pos], ylim[0], ymax,  alpha = 0.5, color=colors_[2],\n",
    "                        label = f'')\n",
    "       \n",
    "    \n",
    "    \n",
    "        xx = ax.get_xlim()\n",
    "        alpha = 0.6\n",
    "        ax.hlines(0, xx[0], xx[1], color = 'grey', alpha = alpha)\n",
    "        ax.hlines(1, xx[0], xx[1], color = 'grey', alpha = alpha)\n",
    "        if p == 'amplitude':\n",
    "            str_= \"[$\\\\mathrm{TeV^{-1}\\\\,s^{-1}\\\\,cm^{-2}}$]\"\n",
    "            plt.xlabel(f\"Source strength \" + str_) \n",
    "        else:\n",
    "            plt.xlabel(p)\n",
    "        plt.ylabel(\"-2log (L) [arb. unit]\")\n",
    "        plt.legend(ncol = 2)\n",
    "\n",
    "    fig.savefig(f\"../{c['folder']}/plots/4_scan_{p}_minos.pdf\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2791ae56-8b0f-4252-8f03-5a4b0cf068f4",
   "metadata": {},
   "source": [
    "## Minos Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e404c-0ba1-4c5b-80d9-5082ddf22ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = \"[10^{-11}/\\\\text{cm}^2 \\\\text{s} \\\\text{TeV}] \"\n",
    "unit2 = \"[\\\\text{TeV}^{-1}]\"\n",
    "print(f\"& &  $\\Phi _0  {unit} $  & $\\Lambda$ & $\\lambda {unit2}$ \\\\\\ \\hline \\hline\")\n",
    "\n",
    "for i, m in enumerate([setup.dataset_helper.models[0],minos_model , minos_model_N]):\n",
    "    if i == 0:\n",
    "        str_  = f\" & Input &\" \n",
    "    if i == 1:\n",
    "        str_  = f\" Bias  &Without fitting &\" \n",
    "        \n",
    "    if i == 2:\n",
    "        str_  = f\" & With fitting  &\" \n",
    "    for j, p in enumerate(['amplitude', 'index', 'lambda_']):\n",
    "        factor = 1\n",
    "        if p == 'amplitude':\n",
    "            factor = 1e11\n",
    "            \n",
    "        if i == 0:\n",
    "            str_  += f\" ${ m.parameters[p].value*factor:.5} $  &\" \n",
    "        if i > 0:\n",
    "            str_  += \" \\error {\" + f\"{m.parameters[p].value*factor:.5}\" + '} { ' + f'{m.parameters[p].error*factor:.3}' + '}  {' + f'{m.parameters[p].error_p*factor:.3}' + '}  {' + f'{m.parameters[p].error_n*factor:.3}' +\"} &\" \n",
    "            \n",
    "    str_ = str_[:-1]\n",
    "    str_ += \"\\\\\\  \"\n",
    "    str_ += \"\\hline\"\n",
    "    print(f\"{str_}\")\n",
    "    str_ = \"\"\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b538db40-be90-48bc-a312-b7e21dd0e634",
   "metadata": {},
   "source": [
    "## Scan Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211385a-3e7c-4496-ae63-423a9cc98c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit = \"[10^{-11}/\\\\text{cm}^2 \\\\text{s} \\\\text{TeV}] \"\n",
    "unit2 = \"[\\\\text{TeV}^{-1}]\"\n",
    "print(f\"& &  $\\Phi _0  {unit} $  & $\\Lambda$ & $\\lambda {unit2}$ \\\\\\ \\hline \\hline\")\n",
    "\n",
    "for i, m in enumerate([setup.dataset_helper.models[0],dataset_asimov.models[0] , \n",
    "                       dataset_asimov_N.models[0]]):\n",
    "    if i == 0:\n",
    "        str_  = f\" & Input &\" \n",
    "    if i == 1:\n",
    "        str_  = f\" Bias  &Without fitting &\" \n",
    "        \n",
    "    if i == 2:\n",
    "        str_  = f\" & With fitting  &\" \n",
    "    for j, p in enumerate(['amplitude', 'index', 'lambda_']):\n",
    "        factor = 1\n",
    "        if p == 'amplitude':\n",
    "            factor = 1e11\n",
    "            \n",
    "        if i == 0:\n",
    "            str_  += f\" ${ m.parameters[p].value*factor:.5} $  &\" \n",
    "        if i > 0:\n",
    "            str_  += \" \\error {\" + f\"{m.parameters[p].value*factor:.5}\" + '} { ' + f'{m.parameters[p].error*factor:.3}' + '}  {' + f'{m.parameters[p].error_p*factor:.3}' + '}  {' + f'{m.parameters[p].error_n*factor:.3}' +\"} &\" \n",
    "            \n",
    "    str_ = str_[:-1]\n",
    "    str_ += \"\\\\\\  \"\n",
    "    str_ += \"\\hline\"\n",
    "    print(f\"{str_}\")\n",
    "    str_ = \"\"\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c57a8-bda1-4748-b9ce-557e9cabffb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86d05a3d-30ec-4185-8bbc-307dbdb9b7f7",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
